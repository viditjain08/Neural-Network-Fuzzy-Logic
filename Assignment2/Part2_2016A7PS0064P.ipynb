{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading necessary packages and defining global variables\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sys import platform\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cpu\")\n",
    "OUTPUT_DIR_TRAIN='data/train.dat'\n",
    "OUTPUT_DIR_TEST='data/test1.dat'\n",
    "\n",
    "NUM_RESTS = 5138\n",
    "NUM_USERS = 3579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_mat(filename):\n",
    "  \n",
    "    '''\n",
    "    \n",
    "    Inputs: \n",
    "        -filename: a string containing the name of the file from which we want\n",
    "                    to extract the data. In our case it can be either train.dat\n",
    "                    or test.dat\n",
    "                    \n",
    "    Returns a python list of size 3579 (number of users) with each element of\n",
    "    the list being a list of tuples (restaurantID, rating).\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    sparse_mat = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            user,res,rating = line.split(',')\n",
    "            while len(sparse_mat)<=int(user):\n",
    "                sparse_mat.append([])\n",
    "            sparse_mat[int(user)].append((int(res),float(rating)))\n",
    "    \n",
    "    return sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have implemented the get_sparse_mat function we can get the train and test sparse matrices\n",
    "train_smat = get_sparse_mat(OUTPUT_DIR_TRAIN)\n",
    "test_smat = get_sparse_mat(OUTPUT_DIR_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X_sam = torch.zeros(5138)\n",
    "        y_sam = torch.zeros(5138)\n",
    "        for i in range(len(self.X[index])):\n",
    "            X_sam[self.X[index][i][0]] = self.X[index][i][1]\n",
    "\n",
    "        for i in range(len(self.y[index])):\n",
    "            y_sam[self.y[index][i][0]] = self.y[index][i][1]\n",
    "\n",
    "        return X_sam, y_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_smat,train_smat)\n",
    "test_dataset = Dataset(train_smat, test_smat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6 if platform == 'linux' else 0}\n",
    "training_generator = data.DataLoader(train_dataset, **params)# sampler = torch.utils.data.SequentialSampler(train_dataset))\n",
    "validation_generator = data.DataLoader(test_dataset, **params)# sampler = torch.utils.data.SequentialSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Define the layers and activation functions to be used in the network.\n",
    "        '''\n",
    "        super(DAE,self).__init__()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        h_size = 128\n",
    "        h_size2 = 32\n",
    "        self.layer1 = nn.Linear(5138,h_size)\n",
    "        self.layer2 = nn.Linear(h_size,h_size2)\n",
    "        self.layer3 = nn.Linear(h_size2,h_size)\n",
    "        self.layer4 = nn.Linear(h_size,5138)\n",
    "        \n",
    "        self.act1 = nn.LeakyReLU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, test=False):\n",
    "        '''\n",
    "        Implement the forward function which takes as input the tensor x and feeds it to the layers of the network\n",
    "        and returns the output.\n",
    "        \n",
    "        Inputs:\n",
    "            -x : Input tensor of shape [N_batch, 5138]\n",
    "            \n",
    "        Returns the output of neural network of shape [N_batch, 5138]\n",
    "        '''\n",
    "        \n",
    "        out = torch.zeros(x.shape[0], 5138)\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        out = self.layer1(x/5)\n",
    "        out = self.act1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.layer4(out)\n",
    "        if test==False:\n",
    "            out=5*self.act2(out)\n",
    "        else:\n",
    "            out = 5*self.act2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(preds, labels):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        -preds: Model predictions [N_batch, 5138]\n",
    "        -labels: User ratings [N_batch, 5138]\n",
    "        \n",
    "    Returns the masked loss as described above.\n",
    "    '''\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    one = torch.ones(labels.shape)\n",
    "    zero = torch.zeros(labels.shape)\n",
    "    mask = torch.where(labels>0,one,zero)\n",
    "    preds = preds*mask\n",
    "    loss_matrix = (preds - labels)**2\n",
    "    loss = torch.sum(loss_matrix)/torch.sum(mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, opti, training_generator, validation_generator, max_epochs = 10):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        - net: The model instance\n",
    "        - criterion: Loss function, in our case it is masked_loss function.\n",
    "        - opti: Optimizer Instance\n",
    "        - training_generator: For iterating through the training set\n",
    "        - validation_generator: For iterating through the test set\n",
    "        - max_epochs: Number of training epochs. One epoch is defined as one complete presentation of the data set.\n",
    "    \n",
    "    Outputs:\n",
    "        - train_losses: a list of size max_epochs containing the average loss for each epoch of training set.\n",
    "        - val_losses: a list of size max_epochs containing the average loss for each epoch of test set.\n",
    "        \n",
    "        Note: We compute the average loss in an epoch by summing the loss at each iteration of that epoch\n",
    "        and then dividing the sum by the number of iterations in that epoch.\n",
    "    '''\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        running_loss = 0 #Accumulate the loss in each iteration of the epoch in this variable\n",
    "        cnt = 0 #Increment it each time to find the number iterations in the epoch.\n",
    "        # Training iterations\n",
    "        for batch_X, batch_y in training_generator:\n",
    "            opti.zero_grad() #Clears the gradients of all variables.\n",
    "            scheduler.step()\n",
    "            # YOUR CODE HERE\n",
    "            output = net(batch_X,False)\n",
    "            loss = criterion(output, batch_X)\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            running_loss+=loss.item()\n",
    "            cnt+=1\n",
    "\n",
    "        print(\"Epoch {}: Training Loss {}\".format(epoch+1, running_loss/cnt))\n",
    "        train_losses.append(running_loss/cnt)\n",
    "        \n",
    "        \n",
    "        #Now that we have trained the model for an epoch, we evaluate it on the test set\n",
    "        running_loss = 0\n",
    "        cnt = 0\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for batch_X, batch_y in validation_generator:\n",
    "\n",
    "                # YOUR CODE HERE\n",
    "                output = net(batch_X,True)\n",
    "                loss = criterion(output, batch_y)\n",
    "                running_loss+=loss.item()\n",
    "                cnt+=1                \n",
    "        print(\"Epoch {}: Validation Loss {}\".format(epoch+1, running_loss/cnt))\n",
    "\n",
    "        val_losses.append(running_loss/cnt)\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss 2.3883015172822133\n",
      "Epoch 1: Validation Loss 1.6128761640616827\n",
      "Epoch 2: Training Loss 0.9497249658618655\n",
      "Epoch 2: Validation Loss 0.8540858307055065\n",
      "Epoch 3: Training Loss 0.7260349169373512\n",
      "Epoch 3: Validation Loss 0.7749890333839825\n",
      "Epoch 4: Training Loss 0.6453759766050747\n",
      "Epoch 4: Validation Loss 0.7105590967195374\n",
      "Epoch 5: Training Loss 0.58583925185459\n",
      "Epoch 5: Validation Loss 0.665977274200746\n",
      "Epoch 6: Training Loss 0.5472237861582211\n",
      "Epoch 6: Validation Loss 0.6425413457410676\n",
      "Epoch 7: Training Loss 0.5262659075004714\n",
      "Epoch 7: Validation Loss 0.6304491119725364\n",
      "Epoch 8: Training Loss 0.5142126248351165\n",
      "Epoch 8: Validation Loss 0.6237762320254531\n",
      "Epoch 9: Training Loss 0.5056282792772565\n",
      "Epoch 9: Validation Loss 0.6185223247323718\n",
      "Epoch 10: Training Loss 0.49900017199771746\n",
      "Epoch 10: Validation Loss 0.6135887216244426\n",
      "Epoch 11: Training Loss 0.49203513615897726\n",
      "Epoch 11: Validation Loss 0.6100382474916322\n",
      "Epoch 12: Training Loss 0.48766848338501795\n",
      "Epoch 12: Validation Loss 0.608157580452306\n",
      "Epoch 13: Training Loss 0.4813538246921131\n",
      "Epoch 13: Validation Loss 0.6049902353967939\n",
      "Epoch 14: Training Loss 0.4765770733356476\n",
      "Epoch 14: Validation Loss 0.6027889262352671\n",
      "Epoch 15: Training Loss 0.47076632029243876\n",
      "Epoch 15: Validation Loss 0.6016403644212655\n",
      "Epoch 16: Training Loss 0.4643357534493719\n",
      "Epoch 16: Validation Loss 0.6008505422089782\n"
     ]
    }
   ],
   "source": [
    "net = DAE()\n",
    "opti = optim.Adam(net.parameters(), lr = 5e-4, weight_decay=1e-06)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=opti, milestones=[i for i in range(20)], gamma=0.98)\n",
    "train_losses, val_losses = train(net, masked_loss, opti, training_generator, validation_generator, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally we plot the graphs for loss vs epochs.\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ratings:  [3.6989436 3.4803524 3.6116233 3.954351  4.3224487]\n",
      "Actual Ratings:  [3.5 3.5 4.  4.  4. ]\n"
     ]
    }
   ],
   "source": [
    "x, y = test_dataset.__getitem__(4)\n",
    "pred = net(x,True)\n",
    "print(\"Predicted Ratings: \", pred[y!=0].detach().numpy())\n",
    "print(\"Actual Ratings: \", y[y!=0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(net, train_data = train_smat):\n",
    "    \n",
    "    def get_test_smat(filename = 'data/test_hidden.dat'):\n",
    "        sparse_dict = defaultdict(list)\n",
    "        for line in open(filename):\n",
    "            splitted_line = line.split(',')\n",
    "            sparse_dict[int(splitted_line[0])].append((int(splitted_line[1])))\n",
    "\n",
    "        sparse_mat = []\n",
    "        sKeys = sorted(sparse_dict)\n",
    "        for key in sKeys:\n",
    "            sparse_mat.append(sparse_dict[key])\n",
    "        \n",
    "        return sparse_mat\n",
    "            \n",
    "            \n",
    "    test_smat = get_test_smat()\n",
    "    preds = []\n",
    "    for i in range(len(train_data)):\n",
    "        \n",
    "        #Getting the actual vector from the sparse representation\n",
    "        x = torch.zeros(5138)\n",
    "        for j in range(len(train_data[i])):\n",
    "            x[train_data[i][j][0]] = train_data[i][j][1]\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = net(x).detach().numpy() ## This logic might be different for your model, change this accordingly\n",
    "        \n",
    "        pred = pred[test_smat[i]]\n",
    "        user_rest_pred = np.concatenate([i*np.ones((len(pred),1),dtype=np.int),np.array(test_smat[i],dtype=np.int)[:,None], np.array(pred)[:,None]],axis = 1)\n",
    "        preds += user_rest_pred.tolist()\n",
    "        \n",
    "    preds = np.array(preds)\n",
    "    df = pd.DataFrame(preds)\n",
    "    df[0] = df[0].astype('int')\n",
    "    df[1] = df[1].astype('int')\n",
    "    df[2] = df[2].astype('float16')\n",
    "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "    df['index1'] = df.index.values\n",
    "    df.columns = ['rating', 'id']\n",
    "    df = df[['id','rating']]\n",
    "    df.to_csv('predictions.csv', index=False, header=True)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.902344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    rating\n",
       "0   0  4.570312\n",
       "1   1  3.589844\n",
       "2   2  3.996094\n",
       "3   3  4.777344\n",
       "4   4  3.902344"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_predictions(net)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
